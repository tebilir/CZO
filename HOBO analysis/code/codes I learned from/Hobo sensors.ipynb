{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Average North Side vs. Average South Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa1 in position 69: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1fc5afc32d9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# read file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv2rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/Eren/Desktop/data/HOBO/Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_of_file\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Eren/anaconda/lib/python3.5/site-packages/matplotlib/mlab.py\u001b[0m in \u001b[0;36mcsv2rec\u001b[0;34m(fname, comments, skiprows, checkrows, delimiter, converterd, names, missing, missingd, use_mrecords, dayfirst, yearfirst)\u001b[0m\n\u001b[1;32m   2883\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m     \u001b[0mprocess_skiprows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mismissing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Eren/anaconda/lib/python3.5/site-packages/matplotlib/mlab.py\u001b[0m in \u001b[0;36mprocess_skiprows\u001b[0;34m(reader)\u001b[0m\n\u001b[1;32m   2878\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_skiprows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2880\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2881\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Eren/anaconda/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa1 in position 69: invalid start byte"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import plot,scatter,savefig,figure,colorbar,suptitle,close,show,subplot,rgrids\n",
    "from matplotlib.mlab import csv2rec\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "from matplotlib.dates import DateFormatter\n",
    "from time import mktime\n",
    "from scipy.interpolate import interp1d\n",
    "import pickle\n",
    "\n",
    "# calibration relationships\n",
    "calnew = csv2rec('/Users/Eren/Desktop/data/HOBO/linregressions.csv')\n",
    "calK = csv2rec('/Users/Eren/Desktop/data/HOBO/calibrations_Kevinsensors.csv')\n",
    "\n",
    "# datafiles\n",
    "files = dict()\n",
    "# 795 = 1-3\n",
    "files['795'] = ['25 August 2010/station1-3.csv','ShuttleReadout12_10_10_10_02_57_AM_PST/2373795.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373795_0.csv','6 Feb 2012/2373795.csv','ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373795.csv',\\\n",
    "    'ShuttleReadout05_07_12_02_07_41_PM_GMT-07_00/2373795_0.csv','ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373795.csv']\n",
    "# 796 = 2-4\n",
    "files['796'] = ['25 August 2010/station2-4.csv','ShuttleReadout10_22_10_08_47_13_AM_PDT/2373796_0.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373796_1.csv','ShuttleReadout09_07_11_05_38_23_PM_PDT/2373796_2.csv',\\\n",
    "    '6 Feb 2012/2373796.csv','ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373796.csv','ShuttleReadout05_07_12_04_56_23_PM_GMT-07_00/2373796.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373796.csv','ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373796_0.csv']\n",
    "# 797 = 2-1\n",
    "files['797'] = ['25 August 2010/station2-1.csv','ShuttleReadout10_22_10_08_47_13_AM_PDT/2373797_0.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373797_1.csv','6 Feb 2012/2373797.csv',\\\n",
    "    'ShuttleReadout05_07_12_02_07_41_PM_GMT-07_00/2373797.csv','ShuttleReadout05_07_12_04_56_23_PM_GMT-07_00/2373797.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373797.csv']\n",
    "# 798 = 1-1\n",
    "files['798'] = ['25 August 2010/station1-1.csv','ShuttleReadout12_10_10_10_02_57_AM_PST/2373798.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373798_0.csv','6 Feb 2012/2373798.csv',\\\n",
    "    'ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373798.csv','ShuttleReadout05_07_12_02_07_41_PM_GMT-07_00/2373798_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373798.csv']\n",
    "# 799 = S-1\n",
    "files['799'] = ['25 August 2010/station3-1.csv','ShuttleReadout10_22_10_08_47_13_AM_PDT/2373799_0.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373799_1.csv','6 Feb 2012/2373799.csv',\\\n",
    "    'ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373799.csv','ShuttleReadout05_07_12_04_22_10_PM_GMT-07_00/2373799.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373799.csv']\n",
    "# 800 = 1-4\n",
    "files['800'] = ['25 August 2010/station1-4.csv','ShuttleReadout12_10_10_10_02_57_AM_PST/2373800.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373800_0.csv','6 Feb 2012/2373800.csv',\\\n",
    "    'ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373800.csv','ShuttleReadout05_07_12_02_07_41_PM_GMT-07_00/2373800_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373800.csv']\n",
    "# 803 = S-3\n",
    "files['803'] = ['25 August 2010/station3-3.csv','ShuttleReadout10_22_10_08_47_13_AM_PDT/2373803_0.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373803_1.csv','6 Feb 2012/2373803.csv',\\\n",
    "    'ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373803.csv','ShuttleReadout05_07_12_04_22_10_PM_GMT-07_00/2373803.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373803.csv']\n",
    "# 804 = 2-3\n",
    "files['804'] = ['25 August 2010/station2-3.csv','ShuttleReadout10_22_10_08_47_13_AM_PDT/2373804_0.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373804_1.csv','ShuttleReadout09_07_11_05_38_23_PM_PDT/2373804_2.csv',\\\n",
    "    '6 Feb 2012/2373804.csv','ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373804.csv',\\\n",
    "    'ShuttleReadout05_07_12_04_56_23_PM_GMT-07_00/2373804.csv','ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373804.csv']\n",
    "# 807 = 1-2\n",
    "files['807'] = ['25 August 2010/station1-2.csv','ShuttleReadout12_10_10_10_02_57_AM_PST/2373807.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373807_0.csv','6 Feb 2012/2373807.csv',\\\n",
    "    'ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373807.csv','ShuttleReadout05_07_12_02_07_41_PM_GMT-07_00/2373807_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373807.csv']\n",
    "# 808 = S-2\n",
    "files['808'] = ['25 August 2010/station3-2.csv','ShuttleReadout10_22_10_08_47_13_AM_PDT/2373808_0.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373808_1.csv','6 Feb 2012/2373808.csv',\\\n",
    "    'ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373808.csv','ShuttleReadout05_07_12_04_22_10_PM_GMT-07_00/2373808.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373808.csv']\n",
    "# 809 = S-4\n",
    "files['809'] = ['6 May 2010/Station3-4.csv','25 August 2010/station3-4.csv',\\\n",
    "    'ShuttleReadout10_22_10_08_47_13_AM_PDT/2373809_0.csv','ShuttleReadout09_07_11_05_38_23_PM_PDT/2373809_1.csv',\\\n",
    "    '6 Feb 2012/2373809.csv','ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373809.csv',\\\n",
    "    'ShuttleReadout05_07_12_04_22_10_PM_GMT-07_00/2373809.csv','ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373809.csv']\n",
    "# 810 = 2-2\n",
    "files['810'] = ['25 August 2010/station2-2.csv','ShuttleReadout10_22_10_08_47_13_AM_PDT/2373810_0.csv',\\\n",
    "    'ShuttleReadout09_07_11_05_38_23_PM_PDT/2373810_1.csv','ShuttleReadout09_07_11_05_38_23_PM_PDT/2373810_2.csv',\\\n",
    "    '6 Feb 2012/2373810.csv','ShuttleReadout03_16_12_12_04_52_PM_GMT-07_00/2373810.csv',\\\n",
    "    'ShuttleReadout05_07_12_04_56_23_PM_GMT-07_00/2373810.csv','ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/2373810.csv']\n",
    "# 40 = ILean 30m\n",
    "files['40'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042540_0_mod.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042540.csv']\n",
    "# 52 = ILean 25m\n",
    "files['52'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042552_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042552.csv']\n",
    "# 44 = ILean 20m\n",
    "files['44'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042544_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042544.csv']\n",
    "# 45 = ILean 15m\n",
    "files['45'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042545_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042545.csv']\n",
    "# 43 = ILean 10m\n",
    "files['43'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042543_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042543.csv']\n",
    "# 36 = ILean 5m\n",
    "files['36'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042536_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042536.csv']\n",
    "# 47 = FT 28m\n",
    "files['47'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042547.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042547.csv']\n",
    "# 56 = FT 22m\n",
    "files['56'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042556.csv',\\\n",
    "    'ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042556_0.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042556.csv']\n",
    "# 35 = FT 17m\n",
    "files['35'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042535.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042535.csv']\n",
    "# 41 = FT 12m\n",
    "files['41'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042541.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042541.csv']\n",
    "# 33 = FT 7m\n",
    "files['33'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042533.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042533.csv']\n",
    "# 49 = FT 2m\n",
    "files['49'] = ['ShuttleReadout05_07_12_03_45_25_PM_GMT-07_00/HydroWatch_10042549.csv',\\\n",
    "    'ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042549.csv']\n",
    "# 62 = Ursula 25 m\n",
    "files['62'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042562.csv']\n",
    "# 58 = Ursula 20 m\n",
    "files['58'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042558.csv']\n",
    "# 54 = Ursula 15 m\n",
    "files['54'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042554.csv']\n",
    "# 61 = Ursula 10 m\n",
    "files['61'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042561.csv']\n",
    "# 42 = Ursula 5 m\n",
    "files['42'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042542.csv']\n",
    "# 59 = SMM 17.5 m\n",
    "files['59'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042559.csv']\n",
    "# 32 = SMM 15 m\n",
    "files['32'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042532.csv']\n",
    "# 60 = SMM 10 m\n",
    "files['60'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042560.csv']\n",
    "# 48 = SMM 5 m\n",
    "files['48'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042548.csv']\n",
    "# 34 = SMM 2.5 m\n",
    "files['34'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042534.csv']\n",
    "# 63 = SMU 17.5 m\n",
    "files['63'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042563.csv']\n",
    "# 37 = SMU 15 m\n",
    "files['37'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042537.csv']\n",
    "# 66 = SMU 10 m\n",
    "files['66'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042566.csv']\n",
    "# 65 = SMU 7.5 m\n",
    "files['65'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042565.csv']\n",
    "# 64 = SMU 5 m\n",
    "files['64'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042564.csv']\n",
    "# 50 = Freddie 30 m\n",
    "files['50'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042550.csv']\n",
    "# 51 = Freddie 24 m\n",
    "files['51'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042551.csv']\n",
    "# 53 = Freddie 18 m\n",
    "files['53'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042553.csv']\n",
    "# 39 = Freddie 12 m\n",
    "files['39'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042539.csv']\n",
    "# 46 = Freddie 6 m\n",
    "files['46'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042546.csv']\n",
    "# 38 = road between well 6 and well 5\n",
    "files['38'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042538.csv']\n",
    "# 57 = near well 15, top of ridge\n",
    "files['57'] = ['ShuttleReadout09_16_12_01_13_41_AM_GMT-07_00/HydroWatch_10042557.csv']\n",
    "\n",
    "# list of sensors placed in the field on May 7 2012\n",
    "latesensors = ['62','58','54','61','42','59','32','60','48','34','63','37','66','65','64','50','51','53','39','46']\n",
    "\n",
    "# loop through sensors\n",
    "sensors = files.keys()\n",
    "sorted(sensors)\n",
    "\n",
    "dt = dict()\n",
    "T = dict()\n",
    "RH = dict()\n",
    "for ss in sensors:\n",
    "    print(ss)\n",
    "    \n",
    "    dttmp = np.array([])\n",
    "    Ttmp = np.array([])\n",
    "    RHtmp = np.array([])\n",
    "    \n",
    "    # loop through files\n",
    "    for ff in files[ss]:\n",
    "        # read file\n",
    "        data = csv2rec('/Users/Eren/Desktop/data/HOBO/Data/'+ff,skiprows=1,comments='!')\n",
    "        fields = data.dtype.names\n",
    "        mask = (data.end_of_file=='')\n",
    "        if 'coupler_detached' in fields:\n",
    "            mask = mask & (data.coupler_detached=='')\n",
    "        if 'coupler_attached' in fields:\n",
    "            mask = mask & (data.coupler_attached=='')\n",
    "        if 'stopped' in fields:\n",
    "            mask = mask & (data.stopped=='')\n",
    "        Ttmp = np.append(Ttmp,data['temp_c'][mask])\n",
    "        RHtmp = np.append(RHtmp,data.rh_[mask])\n",
    "        \n",
    "        # adjust time\n",
    "        if len(ss)==3:\n",
    "            dttmp = np.append(dttmp,(data.date_time_gmt0700[mask]-datetime.timedelta(seconds=3600))) # Kevin's sensors are on daylight savings time - subtract an hour\n",
    "        elif len(ss)==2:\n",
    "            dttmp = np.append(dttmp,data.date_time_gmt0800[mask])\n",
    "            \n",
    "    # exclude non-field data for sensors placed in field on May 7 2012\n",
    "    if ss in latesensors:\n",
    "        mask = dttmp>=datetime.datetime(2012,5,7,17,0,0)\n",
    "        dttmp = dttmp[mask]\n",
    "        Ttmp = Ttmp[mask]\n",
    "        RHtmp = RHtmp[mask]\n",
    "        \n",
    "    # calibrate\n",
    "    if len(ss)==3:\n",
    "        mt = calK.mt[calK.sensor==ss]\n",
    "        bt = calK.bt[calK.sensor==ss]\n",
    "        mrh = calK.mrh[calK.sensor==ss]\n",
    "        brh = calK.brh[calK.sensor==ss]\n",
    "    elif len(ss)==2:\n",
    "        mt = calnew.mt[calnew.sensor==ss]\n",
    "        bt = calnew.bt[calnew.sensor==ss]\n",
    "        mrh = calnew.mrh[calnew.sensor==ss]\n",
    "        brh = calnew.brh[calnew.sensor==ss]\n",
    "        \n",
    "    Ttmp = mt*Ttmp+bt\n",
    "    RHtmp = mrh*RHtmp+brh\n",
    "\n",
    "    # adjust rel hum\n",
    "    RHtmp[RHtmp>100.] = 100.\n",
    "\n",
    "    if ss=='803':\n",
    "        RHtmp = RHtmp+np.nan  # replace bad RH sensor data with nans\n",
    "        \n",
    "    # save date, temp, rel hum\n",
    "    dt[ss] = dttmp\n",
    "    T[ss] = Ttmp\n",
    "    RH[ss] = RHtmp\n",
    "\n",
    "data = dict()\n",
    "data['dt'] = dt\n",
    "data['T'] = T\n",
    "data['RH'] = RH\n",
    "pickle.dump(data, open('HOBOdata.p','wb'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print()\n",
    "\n",
    "#import pickle\n",
    "#with open(\"HOBOdata.p\", \"rb\") as datafile:\n",
    "#        result = cPickle.load(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. By sensor, comparing sensor towers by location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. By location, comparing sensors on opposite sides of the hill at approximately the same altitude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
